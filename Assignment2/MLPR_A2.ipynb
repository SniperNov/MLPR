{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8841743b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ct_support_code import *\n",
    "import numpy as np\n",
    "data = np.load('ct_data.npz')\n",
    "X_train = data['X_train']\n",
    "X_val = data['X_val']\n",
    "X_test = data['X_test']\n",
    "y_train = data['y_train']\n",
    "y_val = data['y_val']\n",
    "y_test = data['y_test']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "514fec1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of y_train:  -9.13868774539957e-15 , with standard error: 0.011926272462733948\n",
      "mean of y_validate:  -0.2160085093241599 , with standard error: 0.012903383410668332\n"
     ]
    }
   ],
   "source": [
    "#Q1.a NEWEST VERSION\n",
    "# print(\"mean of y_train: \",np.mean(y_train))\n",
    "#1.a\n",
    "# standard error = sigma/sqrt(N) = sqrt(variance/N) \n",
    "# report mean with a standard error assuming that each entry is independent\n",
    "N_yvar = y_val.shape[0]\n",
    "mean_yval = np.mean(y_val)\n",
    "mean_ytrn = np.mean(y_train)\n",
    "std_err_yval = np.sqrt(np.var(y_val)/N_yvar)\n",
    "std_err_ytrn = np.sqrt(np.var(y_train[:N_yvar])/N_yvar)\n",
    "print(\"mean of y_train: \",mean_ytrn,\", with standard error:\",std_err_ytrn)\n",
    "print(\"mean of y_validate: \",mean_yval,\", with standard error:\",std_err_yval)\n",
    "\n",
    "\n",
    "# Standard Error bar only give an indication of \n",
    "# how precisely we think we have measured the mean of the distribution with our  samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d4f689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1.b NEWEST VERSION\n",
    "# X_train = np.array([[1,2,3,3,3,5,6,7,8,9,3,5],\n",
    "#               [2,2,4,4,6,7,8,9,0,1,3,6],\n",
    "#               [3,2,5,5,7,8,9,0,8,2,3,7],\n",
    "#               [2,2,4,4,6,7,8,9,0,1,3,6]])\n",
    "# X_test = np.array([[1,2,3,3,3,5,6,7,8,9,3,5],\n",
    "#               [2,2,4,4,6,7,8,9,0,1,3,6],\n",
    "#               [3,2,5,5,7,8,9,0,8,2,3,7],\n",
    "#               [2,2,4,4,6,7,8,9,0,1,3,6]])\n",
    "# X_val = np.array([[1,2,3,3,3,5,6,7,8,9,3,5],\n",
    "#               [2,2,4,4,6,7,8,9,0,1,3,6],\n",
    "#               [3,2,5,5,7,8,9,0,8,2,3,7],\n",
    "#               [2,2,4,4,6,7,8,9,0,1,3,6]])\n",
    "print(\"Size of X_train Before:\",X_train.shape[0],X_train.shape[1])\n",
    "print(\"Size of X_val Before:\",X_val.shape[0],X_val.shape[1])\n",
    "print(\"Size of X_test Before:\",X_test.shape[0],X_test.shape[1])\n",
    "\n",
    "#1 Constant value\n",
    "Xtrain_f_var = np.array(np.var(X_train,axis=0), dtype=bool)\n",
    "Xtrain_feature_removed = np.delete([i for i in range(X_train.shape[1])],Xtrain_f_var)\n",
    "print(\"Index of Xtrain's constant feature discarded = \",Xtrain_feature_removed)\n",
    "X_train = X_train[:,Xtrain_f_var]\n",
    "#2 Duplicate\n",
    "_,index_xtrn = np.unique(X_train, return_index=True, axis=1)\n",
    "Xtrain_sample_removed = np.delete([i for i in range(X_train.shape[1])],index_xtrn)\n",
    "X_train=X_train[:,np.sort(index_xtrn)]\n",
    "print(\"Index of Xtrain's duplicate feature discarded = \",Xtrain_sample_removed)\n",
    "\n",
    "X_val = (X_val[:,Xtrain_f_var])[:,np.sort(index_xtrn)]\n",
    "X_test = (X_test[:,Xtrain_f_var])[:,np.sort(index_xtrn)]\n",
    "\n",
    "print(\"Size of X_train After:\",X_train.shape[0],X_train.shape[1])\n",
    "print(\"Size of X_val After:\",X_val.shape[0],X_val.shape[1])\n",
    "print(\"Size of X_test After:\",X_test.shape[0],X_test.shape[1])\n",
    "\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a4ad8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(w,b,X,y_predicted):\n",
    "    y_actual = np.sum(w*X,axis=1)-b\n",
    "    MSE = np.square(np.subtract(y_actual,y_predicted)).mean() \n",
    "    RMSE = np.sqrt(MSE)\n",
    "    return RMSE\n",
    "\n",
    "\n",
    "#Q2 NEWEST VERSION\n",
    "def fit_linreg(X, yy, alpha):\n",
    "    # Rank+1: for every sample [x1,x2,...,xn]*[w1,w2,...,wn] + b = [x1,x2,...,xn,1]*[w1,w2,...,wn,b]\n",
    "    X_bar = np.vstack([X.T,np.ones(X.shape[0])]).T\n",
    "    # Add K rows to matrix of input features\n",
    "    # Last element in the Kth row should be 0: leave bias b not regularized\n",
    "    temp2 = np.concatenate([np.sqrt(alpha)*np.ones(X_bar.shape[1]-1),[0]])\n",
    "    X_bar2 = np.vstack([X_bar, temp2])\n",
    "    # Add K rows to vector of labels\n",
    "    yy_bar = np.concatenate([yy,[0]])\n",
    "    output= np.linalg.lstsq(X_bar2,yy_bar,rcond=None)[0]\n",
    "    return output\n",
    "\n",
    "\n",
    "output1 = fit_linreg(X_train,y_train,30)\n",
    "w_regularized = output1[0:-1]\n",
    "b_regularized = output1[-1]\n",
    "output2 = fit_linreg_gradopt(X_train,y_train,30)\n",
    "w_gradbased = output2[0]\n",
    "b_gradbased = output2[1]\n",
    "\n",
    "def q2a(setname,X,Y):  \n",
    "    print(\"RMSE on\",setname,\"for regularization = \",RMSE(w_regularized,b_regularized,X,Y))\n",
    "    print(\"RMSE on\",setname,\"for gradient based = \",RMSE(w_gradbased,b_gradbased,X,Y))\n",
    "    \n",
    "q2a(\"training set\",X_train,y_train)\n",
    "q2a(\"validation set\",X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077fc6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3 HELPER FUNCTION\n",
    "def fit_logreg_gradopt(X, yy, alpha):\n",
    "    D = X.shape[1]\n",
    "    args = (X, yy, alpha)\n",
    "    init = (np.zeros(D), np.array(0))\n",
    "    ww, bb = minimize_list(logreg_cost, init, args)\n",
    "    return ww, bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e51dbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3 Newest version\n",
    "\n",
    "K = 20 # number of thresholded classification problems to fit\n",
    "mx = np.max(y_train)\n",
    "mn = np.min(y_train)\n",
    "hh = (mx-mn)/(K+1)\n",
    "probs = np.empty((0,X_train.shape[1]+1))\n",
    "thresholds = np.linspace(mn+hh, mx-hh, num=K, endpoint=True)\n",
    "y_train_binary = np.empty((0,len(y_train)))\n",
    "for kk in range(K):\n",
    "    labels = y_train > thresholds[kk]\n",
    "    y_train_binary = np.row_stack((y_train_binary,labels))\n",
    "    # ... fit logistic regression to these labels\n",
    "    weight,bias = fit_logreg_gradopt(X_train,labels,30)\n",
    "    weight = np.append(weight,bias)\n",
    "    probs = np.row_stack((probs,weight))\n",
    "# shape of probs = (20,374)\n",
    "# column_stack a column of X_train with ones to time with the bias\n",
    "X_trn_temp = np.column_stack((X_train,np.ones(X_train.shape[0])))\n",
    "X_trn_T = np.matmul(X_trn_temp,np.array(probs).T)\n",
    "# X_trn_t.shape = (40754, 20)\n",
    "X_val_temp = np.column_stack((X_val,np.ones(X_val.shape[0]).T))\n",
    "X_val_T = np.matmul(X_val_temp,np.array(probs).T)\n",
    "output3 = fit_linreg(X_trn_T,y_train,30)\n",
    "ww = output3[0:20]\n",
    "bb = output3[20]\n",
    "\n",
    "RMSE_trn = RMSE(ww,bb,X_trn_T,y_train)\n",
    "RMSE_val = RMSE(ww,bb,X_val_T,y_val)\n",
    "print(\"RMSE on Training_Set = \",RMSE_trn)\n",
    "print(\"RMSE on Validation_Set = \",RMSE_val)\n",
    "\n",
    "#RMSE on Training_Set =  2.769307983017384\n",
    "#RMSE on Validation_Set =  2.608896156668959"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fceeeb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4 Newest\n",
    "def initialize_parameters_random(layers_dims):\n",
    "    ww = 0.1* np.random.randn(layers_dims[1]) / np.sqrt(layers_dims[1])\n",
    "    bb = np.zeros(layers_dims[2])\n",
    "    V = 0.1 * (np.random.randn(layers_dims[0], layers_dims[1]) / np.sqrt(layers_dims[0])).T\n",
    "    bk = np.zeros(layers_dims[1])\n",
    "    # print(\"ww.shape=\",ww.shape,\"bb.shape=\",bb.shape,\"V.shape=\",V.shape,\"bk,shape=\",bk.shape)\n",
    "    return [ww, bb, V, bk]\n",
    "\n",
    "def fit_nn_gradopt(X, yy, alpha,layers_dims):\n",
    "    D = X.shape[1]\n",
    "    args = (X, yy, alpha)\n",
    "    init = initialize_parameters_random(layers_dims)\n",
    "    # init = (np.zeros(D), np.array(0))\n",
    "    ww, bb, V, bk = minimize_list(nn_cost, init, args)\n",
    "    return ww, bb, V, bk\n",
    "\n",
    "def question4(X_train,y_train,X_val,y_val,X_test,y_test,alpha):\n",
    "    K = 20\n",
    "    layers_dims = [X_train.shape[1], K, 1]\n",
    "    parameters_a = fit_nn_gradopt(X_train, y_train, alpha, layers_dims)\n",
    "    print(\"*********************finished backward parameter generated**********************\")\n",
    "\n",
    "    RMSE_train_a = np.sqrt(nn_cost(parameters_a, X_train,y_train,30)[0])\n",
    "    RMSE_val_a = np.sqrt(nn_cost(parameters_a, X_val,y_val,30)[0])\n",
    "    RMSE_test_a = np.sqrt(nn_cost(parameters_a, X_test,y_test,30)[0])\n",
    "\n",
    "    parameters_b = question3(X_train,y_train,X_val,y_val,X_test,y_test)\n",
    "    RMSE_train = np.sqrt(nn_cost(parameters_b, X_train, y_train, 30)[0])\n",
    "    RMSE_val_b = np.sqrt(nn_cost(parameters_b, X_val, y_val, 30)[0])\n",
    "    RMSE_test_b = np.sqrt(nn_cost(parameters_b, X_test, y_test, 30)[0])\n",
    "    \n",
    "    print(\"For a) On the train set:\", RMSE_train_a)\n",
    "    print(\"For a) On the validation set:\", RMSE_val_a)\n",
    "    print(\"For a) On the test set:\", RMSE_test_a)\n",
    "    print(\"For b) On the train set:\", RMSE_train_b)\n",
    "    print(\"For b) On the validation set:\", RMSE_val_b)\n",
    "    print(\"For b) On the test set:\", RMSE_test_b)\n",
    "\n",
    "    return parameters_a\n",
    "\n",
    "question4(X_train,y_train,X_val,y_val,X_test,y_test,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8301ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5 Newest\n",
    "def train_nn_reg(X_train,y_train,X_val,y_val,alpha):\n",
    "    K = 20\n",
    "    layers_dims = [X_train.shape[1], K, 1]\n",
    "    parameters = fit_nn_gradopt(X_train, y_train, alpha, layers_dims)\n",
    "    RMSE_val = np.sqrt(nn_cost(parameters, X_val,y_val,30)[0])\n",
    "    return RMSE_val\n",
    "\n",
    "def maxPI(test_loc,ob_loc,bl_alpha,X_train,y_train,X_val,y_val):\n",
    "    ob_val = []\n",
    "    blRMSE = np.log(train_nn_reg(X_train,y_train,X_val,y_val,30))\n",
    "    for loc in ob_loc：\n",
    "        n1RMSE = b1RMSE - np.log(train_nn_reg(X_train,y_train,X_val,y_val,bl_alpha))\n",
    "        ob_val.append(n1RMSE)\n",
    "    rest_cond_mu, rest_cond_cov = gp_post_var(test_loc,ob_loc,ob_val)\n",
    "    bla_mu,_ = gp_post_var(test_loc,bl_alphal,b1RMSEB V)\n",
    "    max_obs = max(ob_val)\n",
    "    outputs = (rest_cond_mu - max_obs)/np.diagonal(rest_cond_cov)\n",
    "    next_alpha = max(outputs)\n",
    "    return alpha\n",
    "\n",
    "alphas = np.arange(0, 50, 0.02)\n",
    "alpha_chosen = np.random.choice(alphas,3)\n",
    "alpha_remain = np.remove(alphas,alpha_remain)\n",
    "result_y = []\n",
    "blRMSE = np.log(train_nn_reg(X_train,y_train,X_val,y_val,30))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83066256",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
